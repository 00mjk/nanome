params {
	//##################################################################
	//############### Reserved by Lifebit CloudOS settings #############
	//##################################################################
	//##################################################################
	// gpu related params
	containerOptions = '--gpus all'
	accelerator  = 'nvidia-tesla-p100'
	n_accelerators = 1
	with_gpus_process_cpus = 4
	with_gpus_process_memory = '24.GB'

	// resquiggle resource allocation
	resquiggle_cpus = 8
	resquiggle_memory = '32.GB'

	// configuration for Lifebit running Docker container
	containerName="quay.io/liuyangzzu/nanome:v1.4"
	echo = false
	config = 'conf/standard.config'
	executor = false
	gls_bootDiskSize = '50.GB'
	gls_preemptible = true
	zone = 'us-east1-b'
	network = 'jax-cloudos-shengli-vpc'
	subnetwork =  'cloudos-subnet'
	queueSize = 200
	//##################################################################
	//########################### End of block #########################
	//##################################################################
	//##################################################################
	// nanome running software env
	conda_name="/home/liuya/anaconda3/envs/nanocompare"
	docker_name="quay.io/liuyangzzu/nanome:v1.4"
	singularity_name='docker://quay.io/liuyangzzu/nanome:v1.4'
	singularity_cache_dir='/fastscratch/li-lab/nanome/singularity-cache'

	// Default input params for pipeline running
	dsname = 'TestData'
	input = 'https://raw.githubusercontent.com/liuyangzzu/nanome/master/inputs/test.demo.filelist.txt'
	outputDir="outputs"

	runid = "TestData_RRBS"
	bgEncode='bismark'
	// bgTruth = '/projects/li-lab/Nanopore_compare/data/NA19240/NA19240_RRBS_ENCFF000LZS_rep1.Read_R1.Rep_1_trimmed_bismark_bt2.CpG_report.txt.gz;/projects/li-lab/Nanopore_compare/data/NA19240/NA19240_RRBS_ENCFF000LZT_rep2.Read_R1.Rep_2_trimmed_bismark_bt2.CpG_report.txt.gz'
	bgTruth = ''
	bgtruth_cov=1
	tool_cov=1

	// Reference genome from online inputs
	dataType="human"  // can be human, ecoli, etc.
	referenceGenome="reference_genome/hg38/hg38.fasta"
	chromSizesFile="reference_genome/hg38/hg38.chrom.sizes"
	//##################################################################
	//############### Reserved by tools default settings ###############
	//##################################################################
	//##################################################################
	// Default tool running configuration
	runNanopolish=true
	runMegalodon=true
	runDeepSignal=true
	runGuppy=true
	runTombo=true
	runDeepMod=true
	runResquiggle=true
	runCombine=true

	// Split tasks for two platform in JAX, true if only run GPU tasks
	filterGPUTaskRuns=false

	runBasecall=true
	runMethcall=true

	// if perform evaluations after callings
	eval=false

	// Resquiggle specifications
	BasecallGroupName="Basecall_1D_000" // Basecall ID name used by resquiggle
	cleanAnalyses=false // true if clean previous analysis in fast5 inputs
	resquiggleCorrectedGroup="RawGenomeCorrected_000"

	// DeepMod options
	DeepModMoveOptions="--move" // options of Guppy basecalled input for DeepMod, empty for Albacore usage
	chrSet="" //used by DeepMod, default "" means all Human chromosomes, else need to specify such as chr1,chr2

	// Guppy model specificatoins
	// Suggested model by Guppy basecall
	GUPPY_BASECALL_MODEL="dna_r9.4.1_450bps_hac.cfg"
	// Suggested model by Guppy methcall
	GUPPY_METHCALL_MODEL="dna_r9.4.1_450bps_modbases_dam-dcm-cpg_hac.cfg"

	// The suggested model and options by Megalodon
	MEGALODON_MODEL_FOR_GUPPY_CONFIG="res_dna_r941_min_modbases_5mC_v001.cfg"
	GUPPY_TIMEOUT = 240
	READS_PER_GUPPY_BATCH = 100
	SAMTOOLS_PATH="samtools"

	// DeepMod default used model specifications
	DeepModGithub="https://github.com/WGLab/DeepMod/archive/refs/tags/v0.1.3.tar.gz"
	DEEPMOD_RNN_MODEL="rnn_conmodC_P100wd21_f7ne1u0_4/mod_train_conmodC_P100wd21_f3ne1u0"
	DEEPMOD_CLUSTER_MODEL="na12878_cluster_train_mod-keep_prob0.7-nb25-chr1/Cg.cov5.nb25"
	// for deep-learning jobs, we use processors*times as multiprocessing options
	deepLearningProcessorTimes=8

	// Default nanome pipeline input data settings
	processors = 4
	untarProcessors = 16
	deepmod_ctar = "/projects/li-lab/Nanopore_compare/nf_input/C.tar.gz"
	genome_annotation_tar = "/projects/li-lab/Nanopore_compare/nf_input/genome-annotation.tar.gz"
	// reference_genome_tar = "/projects/li-lab/Nanopore_compare/nf_input/reference_genome.tar.gz"
	reference_genome_tar = '/projects/li-lab/Nanopore_compare/nf_input/reference_genome'
	deepsignal_model_tar = "/projects/li-lab/Nanopore_compare/nf_input/model.CpG.R9.4_1D.human_hx1.bn17.sn360.v0.1.7+.tar.gz"
	megalodon_model_tar = "/projects/li-lab/Nanopore_compare/nf_input/megalodon_model.tar.gz"

	//##################################################################
	//######################### End of block ###########################
	//##################################################################
	//##################################################################

	//##################################################################
	//############### Reserved by google cloud computing ###############
	//##################################################################
	//##################################################################
	// Google cloud computing configurations defaults
	// used for google computing platform
	glsContainerName = 'us.gcr.io/jax-nanopore-01/nanome:v1.4'
	max_retries = 4

	machineTypeLowCost = 'custom-8-32768'
	gpuTypeLowCost = 'nvidia-tesla-p100'
	gpuNumberLowCost=1

	machineType = "n1-highmem-16"
	gpuType = 'nvidia-tesla-p100'
	gpuNumber=1

	//	lowDiskSize = 200.GB // for test and check
	//	midDiskSize = 400.GB // for methylation
	//	highDiskSize = 850.GB // for untar, basecall and resquiggle

	lowDiskSize = 100.GB // for test and check
	midDiskSize = 150.GB // for methylation
	highDiskSize = 200.GB // for untar, basecall and resquiggle
	//##################################################################
	//########################## End of block ##########################
	//##################################################################
	//##################################################################
}

// Running on different platforms
profiles {
	docker {
		process.container = params.docker_name
		docker.enabled = true
	}
	
	standard { includeConfig params.config }

	winter_conda { // conda in HPC support
		executor.name ='slurm'
		process.conda = "${params.conda_name}"
		process.cache = 'lenient'
		// Slurm options for winter HPC
		process.queue = 'gpu'
		process.clusterOptions = "-q inference -n ${params.processors} --gres=gpu:1 --time=06:00:00 --mem=170G"
		process.beforeScript = 'export computeName=gpu; module load singularity'

		// Guppy gpu dir
		params.GuppyDir = "/projects/li-lab/software/ont-guppy-gpu_4.2.2"
		// Export Guppy dir to env
		env.PATH = "${params.GuppyDir}/bin:$PATH"
		// process.beforeScript not function, so we export env
		env.computeName = "gpu"
		env.numProcessor = "${params.processors}"
	}

	sumner_conda {
		executor.name = 'slurm'
		process.conda = "${params.conda_name}"
		process.cache = 'lenient'
		// Slurm options for sumner HPC
		process.queue = 'compute'
		process.clusterOptions = "-q batch -n ${params.processors} --time=72:00:00 --mem=270G"
		process.beforeScript = 'export computeName=cpu; module load singularity'

		// Guppy cpu dir
		params.GuppyDir = "/projects/li-lab/software/ont-guppy-cpu_4.2.2"
		//Export Guppy dir to env
		env.PATH = "${params.GuppyDir}/bin:$PATH"
		// process.beforeScript not function, so we export env
		env.computeName = "cpu"
		env.numProcessor = "${params.processors}"
	}

	winter_singularity { // singularity support
		process.executor = 'slurm'
		process.cache = 'lenient'
		process.container = params.singularity_name
		// Slurm options for winter HPC
		process.queue = 'gpu'
		process.clusterOptions = "-q inference -n ${params.processors} --gres=gpu:1 --time=06:00:00 --mem=180G"
		process.beforeScript = 'module load singularity; export computeName=gpu'

		singularity {
			enabled = true
			autoMounts = true
			cacheDir = params.singularity_cache_dir
		}
		// process.beforeScript not function, so we export env
		env.computeName = "gpu"
		env.numProcessor = "${params.processors}"
	}

	sumner_singularity {
		process.executor = 'slurm'
		process.cache = 'lenient'
		process.container = params.singularity_name

		// Slurm options for winter HPC
		process.queue = 'compute'
		process.clusterOptions = "-q batch -n ${params.processors} --time=72:00:00 --mem=280G"
		process.beforeScript = 'module load singularity; export computeName=cpu'

		singularity {
			enabled = true
			autoMounts = true
			cacheDir = params.singularity_cache_dir
		}
		// process.beforeScript not function, so we export env
		env.computeName = "cpu"
		env.numProcessor = "${params.processors}"
	}

	// Google cloud computing platform
	google_cloud {
		executor {
			name = 'google-lifesciences'
			pollInterval = '30 sec'
		}
		docker {
			enabled = true
			temp = 'auto'
		}
		google.project = 'jax-nanopore-01'
		//google.zone = 'us-east1-c'
		google.location = 'us' // 'us'
		google.region = 'us-east1'	// 'us-east1'
		google.lifeSciences.debug = true
		google.lifeSciences.preemptible = true
		google.lifeSciences.usePrivateAddress = false
		google.lifeSciences.sshDaemon = true
		google.lifeSciences.bootDiskSize = 30.GB
		google.enableRequesterPaysBuckets = true
		google.lifeSciences.network = 'default'
		google.lifeSciences.subnetwork = 'default'

		// Include nanome input from google cloud params
		includeConfig 'conf/gc_params.config'

		// process.beforeScript not function, so we export env
		env.computeName = "gpu"
		env.numProcessor = "${params.processors}"
		env.PYTHONPATH = "/opt/bin/src"

		process {
			container = params.glsContainerName
			machineType = params.machineType
			disk = params.midDiskSize
			maxRetries = params.max_retries
			errorStrategy = {task.attempt == process.maxRetries ? 'ignore' :  task.exitStatus in [8, 10, 14 ] ? 'retry' : 'ignore' }
			cache = 'lenient'
			beforeScript = 'export computeName=gpu'

			// withName must inherit process attributes
			withName: EnvCheck {
				machineType = params.machineTypeLowCost
				disk = params.lowDiskSize  // need enough spaces for genome reference, such as +   150.GB * task.attempt
				accelerator = [request:  params.gpuNumberLowCost, type: params.gpuTypeLowCost ]
			}

			withName: Untar {
				machineType = params.machineType
				errorStrategy = { task.attempt == process.maxRetries ? 'ignore' : task.exitStatus in [9, 14] ? 'retry' : 'ignore' }
			}

			withName: Basecall {
				machineType = params.machineType
				accelerator = [request:  params.gpuNumber, type: params.gpuType ]
				errorStrategy = { task.attempt == process.maxRetries ? 'ignore' : task.exitStatus in [9, 14] ? 'retry' : 'ignore' }
			}

			withName: Guppy {
				machineType = params.machineType
				accelerator = [request:  params.gpuNumber, type: params.gpuType ]
				errorStrategy = { task.attempt == process.maxRetries ? 'ignore' : task.exitStatus in [9, 14] ? 'retry' : 'ignore' }
			}

			withName: Megalodon {
				machineType = params.machineType
				accelerator = [request:  params.gpuNumber, type: params.gpuType ]
				errorStrategy = { task.attempt == process.maxRetries ? 'ignore' : task.exitStatus in [9, 14] ? 'retry' : 'ignore' }
			}

			withName: DeepSignal {
				machineType = params.machineType
				accelerator = [request:  params.gpuNumber, type: params.gpuType ]
				disk = params.midDiskSize
			 	errorStrategy = { task.attempt == process.maxRetries ? 'ignore' : task.exitStatus in [8, 10, 14 ] ? 'retry' : 'ignore' }
			}

			withName: Resquiggle {
				machineType = params.machineType
				errorStrategy = { task.attempt == process.maxRetries ? 'ignore' : task.exitStatus in [9, 14] ? 'retry' : 'ignore' }
			}

			withName: Tombo {
				machineType = params.machineType
				disk = params.midDiskSize
				errorStrategy = { task.attempt == process.maxRetries ? 'ignore' : task.exitStatus in [14, 32] ? 'retry' : 'ignore' }
			}

			withName: Nanopolish {
				machineType = params.machineType  // 130GB memory
				errorStrategy = { task.attempt == 5 ? 'ignore' : task.exitStatus in [14, 139] ? 'retry' : 'ignore' }
			}
		}
	}
}

executor {
	name = params.executor
	queueSize = params.queueSize
}

manifest {
	homePage = 'https://nanome.jax.org'
	description = 'The nanome Pipeline of DNA methylation-calling tools for Oxford Nanopore sequencing'
	mainScript = 'main.nf'
	version = '1.0'
}
