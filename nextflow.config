params {
	//##################################################################
	//################Reserved by LifeBit Cloud settings################
	//##################################################################
	//##################################################################
	//gpu related params
	containerOptions = '--gpus all'
	accelerator  = 'nvidia-tesla-p100'
	n_accelerators = 1
	with_gpus_process_cpus = 4
	with_gpus_process_memory = '24.GB'

	// resquiggle resource allocation
	resquiggle_cpus = 8
	resquiggle_memory = '32.GB'

	// configuration for Lifebit running Docker container
	//containerName="quay.io/lifebitai/nanome:shebang-cuda"
	containerName="quay.io/liuyangzzu/nanome:v1.3"
	echo = false
	config = 'conf/standard.config'
	executor = false
	gls_bootDiskSize = '50.GB'
	gls_preemptible = true
	zone = 'us-east1-b'
	network = 'jax-cloudos-shengli-vpc'
	subnetwork =  'cloudos-subnet'
	queueSize = 200
	//##################################################################
	//##############################End of block########################
	//##################################################################
	//##################################################################
	//Default input params
	dsname = 'TestData'
	input = 'https://github.com/liuyangzzu/nano-compare/raw/master/test_data/demo.fast5.reads.tar.gz'
	outputDir="outputs"

	eval=false // if perform evaluations after callings
	runBasecall=true
	runMethcall=true

	runid = "TestData_RRBS"
	bgtruthWithEncode="bismark:/projects/li-lab/Nanopore_compare/data/NA19240/NA19240_RRBS_ENCFF000LZS_rep1.Read_R1.Rep_1_trimmed_bismark_bt2.CpG_report.txt.gz;/projects/li-lab/Nanopore_compare/data/NA19240/NA19240_RRBS_ENCFF000LZT_rep2.Read_R1.Rep_2_trimmed_bismark_bt2.CpG_report.txt.gz"
	bgtruth_cov=5
	tool_cov=3

	// used for HPC
	condaEnvName="/home/liuya/anaconda3/envs/nanome"

	// Reference genome from online inputs
	referenceGenome="reference_genome/hg38/hg38.fasta"
	chromSizesFile="reference_genome/hg38/hg38.chrom.sizes"
	dataType="human"  // can be human, ecoli, etc.

	//##################################################################
	//################Reserved by tools default settings################
	//##################################################################
	//##################################################################
	//Default tool settings and params
	runResquiggle=true
	runTombo=true
	runDeepSignal=true
	runDeepMod=true
	runGuppy=true
	runMegalodon=true
	runNanopolish=true

	// Download method: wget, aws, etc.
	downloadMethod="wget"

	// Used for DeepSignal gpu support
	DeepSignal_isgpu = 'yes'

	// Resquiggle specifications/options
	BasecallGroupName="Basecall_1D_000" // Basecall ID name used by resquiggle
	cleanAnalyses=false // true if clean previous analysis in fast5 inputs
	resquiggleCorrectedGroup="RawGenomeCorrected_000"

	// DeepMod options
	DeepModMoveOptions="--move" // options of Guppy basecalled input for DeepMod, empty for Albacore usage
	DeepModSumChrSet="" //used by DeepMod, default "" means all Human chromosomes, else need to specify such as chr1,chr2

	// Guppy model specificatoins
	// Suggested model by Guppy basecall
	GUPPY_BASECALL_MODEL="dna_r9.4.1_450bps_hac.cfg"
	// Suggested model by Guppy methcall
	GUPPY_METHCALL_MODEL="dna_r9.4.1_450bps_modbases_dam-dcm-cpg_hac.cfg"
	// Guppy gpu options
	GuppyGPUOptions="--gpu_runners_per_device 16 --device auto"
	GuppyNumCallers=16

	//The suggested model and options by Megalodon
	MEGALODON_MODEL_FOR_GUPPY_CONFIG="res_dna_r941_min_modbases_5mC_v001.cfg"
	GUPPY_TIMEOUT = 240
	READS_PER_GUPPY_BATCH = 100
	SAMTOOLS_PATH="samtools"
	megalodonGPUOptions="--devices 0 1"

	// DeepMod default used model specifications
	DeepModGithub="https://github.com/WGLab/DeepMod/archive/refs/tags/v0.1.3.tar.gz"
	deepModModel="rnn_conmodC_P100wd21_f7ne1u0_4/mod_train_conmodC_P100wd21_f3ne1u0"
	clusterDeepModModel="na12878_cluster_train_mod-keep_prob0.7-nb25-chr1/Cg.cov5.nb25"

	//Default nanome pipeline input data
	processors = 8
	deepmod_ctar = "/projects/li-lab/Nanopore_compare/nf_input/C.tar.gz"
	genome_annotation_tar = "/projects/li-lab/Nanopore_compare/nf_input/genome-annotation.tar.gz"
	reference_genome_tar = "/projects/li-lab/Nanopore_compare/nf_input/reference_genome.tar.gz"
	deepsignel_model_tar = "/projects/li-lab/Nanopore_compare/nf_input/model.CpG.R9.4_1D.human_hx1.bn17.sn360.v0.1.7+.tar.gz"
	megalodon_model_tar = "/projects/li-lab/Nanopore_compare/nf_input/megalodon_model.tar.gz"

	//##################################################################
	//##############################End of block########################
	//##################################################################
	//##################################################################

	//##################################################################
	//################Reserved by google cloud computing################
	//##################################################################
	//##################################################################
	// Google cloud computing configurations defaults
	// used for google computing platform
	glsContainerName = 'us.gcr.io/jax-nanopore-01/nanome:v1.4'

	machineTypeLowCost = 'custom-8-32768'
	gpuTypeLowCost = 'nvidia-tesla-p100'
	gpuNumberLowCost=1

	machineType = "n1-highmem-16"
	gpuType = 'nvidia-tesla-p100'
	gpuNumber=1

	lowDiskSize = '200 GB' // for test and check
	midDiskSize = '400 GB' // for methylation
	highDiskSize = '850 GB' // for untar, basecall and resquiggle
	//##################################################################
	//##############################End of block########################
	//##################################################################
	//##################################################################
}

// Running on different platforms
profiles {

	docker {
		process.container="quay.io/lifebitai/nanome:shebang-cuda"
		docker.enabled = true
	}
	
	standard { includeConfig params.config }

	winter { // run on HPC winter GPU settings
		executor.name ='slurm'
		process.conda="${params.condaEnvName}"
		process.cache = 'lenient'

		// Include tools' gpu specific options
		includeConfig 'conf/tool_options_on_gpu.config'

		// Guppy gpu dir
		params.GuppyDir="/projects/li-lab/software/ont-guppy-gpu_4.2.2"
		// Export Guppy dir to env
		env.PATH = "${params.GuppyDir}/bin:$PATH"

		// Slurm options for winter HPC
		process.queue='gpu'
		process.clusterOptions="-q inference -n ${params.processors} --gres=gpu:1 --time=06:00:00 --mem=70G"
	}

	sumner {
		executor.name ='slurm'
		process.conda="${params.condaEnvName}"
		process.cache = 'lenient'

		// run on HPC sumner with CPU support
		includeConfig 'conf/hpc.config'

		// Include tools' cpu specific options
		includeConfig 'conf/tool_options_on_cpu.config'

		// Guppy cpu dir
		params.GuppyDir="/projects/li-lab/software/ont-guppy-cpu_4.2.2"
		//Export Guppy dir to env
		env.PATH = "${params.GuppyDir}/bin:$PATH"
		// Slurm options for sumner HPC
		process.queue='compute'
		process.clusterOptions="-q batch -n ${params.processors} --time=72:00:00 --mem=70G"

		process.echo = params.echo
	}

	sumner2 {
		process.executor = 'slurm'
		process.beforeScript = 'module load singularity'
		singularity {
			enabled = true
			autoMounts = true
		}
	}

	// Google cloud computing platform
	gls {
		executor {
			name = 'google-lifesciences'
			//queueSize = 200
			pollInterval = '60 sec'
		}
		docker {
			enabled = true
			temp = 'auto'
		}
		google.project = 'jax-nanopore-01'
		//google.zone = 'us-east1-c'
		google.location = 'us' // 'us'
		google.region  = 'us-east1'	// 'us-east1'
		google.lifeSciences.debug = true
		google.lifeSciences.preemptible = true
		google.lifeSciences.usePrivateAddress = false
		google.lifeSciences.sshDaemon = true
		google.lifeSciences.bootDiskSize = '40 GB'
		google.enableRequesterPaysBuckets = true
		google.lifeSciences.network = 'default'
		google.lifeSciences.subnetwork = 'default'

		// Include tools' gpu specific options
		params.processors=16
		includeConfig 'conf/tool_options_on_gpu.config'

		// Include nanome input from google cloud storage
		includeConfig 'conf/gcp.config'

		process {
			container = params.glsContainerName
			machineType = params.machineType
			disk = params.midDiskSize
			errorStrategy = { task.exitStatus==14  ? 'retry' : 'terminate' }
  			maxRetries = 5
			cache = 'lenient'
			echo = params.echo

			// withName must inherit process attributes
			withName: EnvCheck {

				machineType = params.machineTypeLowCost
				disk = params.lowDiskSize  // need enough spaces for genome reference, such as +   150.GB * task.attempt
				accelerator = [request:  params.gpuNumberLowCost, type: params.gpuTypeLowCost ]
			}

			withName: Untar {
				machineType = params.machineType
				//disk is dynamic determined by input size
				//disk = params.highDiskSize
				errorStrategy = { task.exitStatus in [9, 14] ? 'retry' : 'terminate' }
			}

			withName: Basecall {
				machineType = params.machineType
				accelerator = [request:  params.gpuNumber, type: params.gpuType ]
				disk = params.highDiskSize
				errorStrategy = { task.exitStatus in [9, 14] ? 'retry' : 'terminate' }
			}

			withName: Guppy {
				machineType = params.machineType
				accelerator = [request:  params.gpuNumber, type: params.gpuType ]
				errorStrategy = { task.exitStatus in [9, 14] ? 'retry' : 'terminate' }
			}

			withName: Megalodon {
				machineType = params.machineType
				disk = params.midDiskSize
				accelerator = [request:  params.gpuNumber, type: params.gpuType ]
			}

			withName: DeepSignal {
				machineType = params.machineType
				disk = params.midDiskSize
				//reduce costs
				//accelerator = [request:  params.gpuNumber, type: params.gpuType ]
			}

			withName: Resquiggle {
				machineType = params.machineType
				disk = params.highDiskSize
				errorStrategy = { task.exitStatus in [9, 14] ? 'retry' : 'terminate' }
			}

			withName: Tombo {
				machineType = params.machineType
				disk = params.midDiskSize
				errorStrategy = { task.exitStatus in [14, 32] ? 'retry' : 'terminate' }
			}

		}
	}
}

executor {
	name = params.executor
	queueSize = params.queueSize
}

manifest {
	homePage = 'https://nanome.jax.org'
	description = 'The nanome Pipeline of evaluation DNA methylation calling tools for Oxford Nanopore sequencing'
	mainScript = 'main.nf'
	version = '1.0.0'
}


def extractBaseName(filePath) {
	return fast5_tar.lastIndexOf('/').with {it != -1 ? fast5_tar.substring(it+1) : fast5_tar}
}

// Function to ensure that resource requirements don't go beyond
// a maximum limit
def check_max(obj, type) {
  if (type == 'memory') {
    try {
      if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
        return params.max_memory as nextflow.util.MemoryUnit
      else
        return obj
    } catch (all) {
      println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
      return obj
    }
  } else if (type == 'time') {
    try {
      if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
        return params.max_time as nextflow.util.Duration
      else
        return obj
    } catch (all) {
      println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
      return obj
    }
  } else if (type == 'cpus') {
    try {
      return Math.min( obj, params.max_cpus as int )
    } catch (all) {
      println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
      return obj
    }
  } else if (type == 'disk') {
    try {
      return obj
    } catch (all) {
      println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
      return obj
    }
  }
}
